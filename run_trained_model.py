# -*- coding: utf-8 -*-
"""“skeleton_code.ipynb”的副本

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13d3Ur9_5t7EDF6zVHdtTyBN97ZEMLscP

# Skeleton code


Here is some skeleton code to get you started. We will provide you with the dataset loading and evaluation code. You will need to design a model that takes in the .wav files, and outputs a label.

## Class Label
- Ben Franklin statue - Google Map "Ben on the Bench"
- Blackboard (not white board) - Levine 4th floor bump space
- Table - Levine 4th floor near window
- Glass window - Levine 4th floor
- Handrail - Levine 4th floor
- Water fountain - Levine 4th floor
- Sofa - Levine 4th floor bump space


### 1. Multi-Class Classification with Logistic Regression
"""

import os
import librosa
import numpy as np
import joblib

from google.colab import drive
drive.mount('/content/drive/')

eval_folder = "/content/drive/Shareddrives/(TA Team Drive) CIS 4190 5190 Applied Machine Learning Fall 2024/[Project] Sound-based Material Classification/Data"
# eval_folder = "/content/drive/My Drive/Audio_Project/test_data"
print([d for d in os.listdir(eval_folder)])

CLASS_TO_LABEL = {
    'water': 0,
    'table': 1,
    'sofa': 2,
    'railing': 3,
    'glass': 4,
    'blackboard': 5,
    'ben': 6,
}

LABEL_TO_CLASS = {v: k for k, v in CLASS_TO_LABEL.items()}

# Set the base directory path
base_dir = eval_folder
X = []
Y = []
# Loop through subfolders
for idx, class_folder in enumerate(os.listdir(base_dir)):
    class_folder_path = os.path.join(base_dir, class_folder)

    # Check if it's a directory
    if os.path.isdir(class_folder_path):
        y = CLASS_TO_LABEL[class_folder]
        for sample in os.listdir(class_folder_path):
            file_path = os.path.join(class_folder_path, sample)
            X.append(file_path)
            Y.append(y)
X = np.array(X)
Y = np.array(Y)

print(X.shape)
print(Y.shape)
print(X[::10])
print(Y[::10])

"""# Model definition
When we evaluate your model, we expect that you provide your model weights and model setup in this codeblock.

Make sure your model weights are public!
"""

def run_trained_model(X):
  # X is of shape (N, ), where each element is a path string to a WAV file.
  # TODO: featurize the WAV files
  def extract_features(audio_path: str) -> np.ndarray:
      # config of WAV
      y, sr = librosa.load(
          audio_path,
          duration=3,
          sr=22050
      )
      # Extracting MFCC features
      mfcc = librosa.feature.mfcc(
          y=y,
          sr=sr,
          n_mfcc=20
      )
      # Extracting spectral features
      spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
      spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
      zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]

      # Convert all features to 1D arrays
      mfcc_mean = np.mean(mfcc, axis=1)
      mfcc_std = np.std(mfcc, axis=1)
      mfcc_25 = np.percentile(mfcc, 25, axis=1)
      mfcc_75 = np.percentile(mfcc, 75, axis=1)

      spectral_centroids_mean = np.mean(spectral_centroids)
      spectral_centroids_std = np.std(spectral_centroids)
      spectral_rolloff_mean = np.mean(spectral_rolloff)
      spectral_rolloff_std = np.std(spectral_rolloff)
      zero_crossing_rate_mean = np.mean(zero_crossing_rate)
      zero_crossing_rate_std = np.std(zero_crossing_rate)

      # Combine spectral features
      scalar_features = np.array([
          spectral_centroids_mean,
          spectral_centroids_std,
          spectral_rolloff_mean,
          spectral_rolloff_std,
          zero_crossing_rate_mean,
          zero_crossing_rate_std
      ])

      # Combine mfcc features
      features = np.concatenate([
          mfcc_mean,
          mfcc_std,
          mfcc_25,
          mfcc_75,
          scalar_features
      ])

      return features

  # TODO: load model weights
  def download_model_weights():
    import gdown
    url = 'https://drive.google.com/file/d/1hnRt75VDLKY0qZE3NtAf89BVh6roglBP/view?usp=drive_link'
    best_model = 'best_model.pkl'
    gdown.download(url, best_model, fuzzy=True)
    return best_model
  weight_path = download_model_weights()
  model = joblib.load(weight_path)

  # TODO: load data scale
  def download_model_weights():
    import gdown
    url = 'https://drive.google.com/file/d/1jVU8SVHQLPpQP3GCuu2-S-WJ1QN_Jfya/view?usp=drive_link'
    best_scaler = 'scaler.pkl'
    gdown.download(url, best_scaler, fuzzy=True)
    return best_scaler
  scaler_path = download_model_weights()
  scaler = joblib.load(scaler_path)

  # TODO: setup model
  def predict_file(X):
    results = []
    for path in X:
      # Extract features
      features = extract_features(path)
      features = features.reshape(1, -1)

      # Standardized features
      features = scaler.transform(features)

      # Prediction
      prediction = model.predict(features)[0]
      # Replacement Index (Comply with skeleton requirements)
      if prediction == 0:
        prediction = 1
      elif prediction == 1:
        prediction = 0
      elif prediction == 3:
        prediction = 4
      elif prediction == 4:
        prediction = 5
      elif prediction == 5:
        prediction = 3

      # print(prediction)
      results.append(prediction)
      predictions = np.array(results)

    return predictions

  predictions = predict_file(X) # Should be shape (N,) where each element is a class integer for the corresponding data point.
  assert predictions.shape == Y.shape
  return predictions

from sklearn.metrics import accuracy_score

Y_pred = run_trained_model(X)
accuracy = accuracy_score(Y, Y_pred)
print("---------------")
print(f"\nModel Accuracy on unseen data: {accuracy:.4f}")

from collections import defaultdict

Y = np.array(Y)
Y_pred = np.array(Y_pred)
# Initialize a dictionary to store accuracies
per_class_accuracy = {}
# Calculate accuracy for each class
unique_classes = np.unique(Y)
for cls in unique_classes:
    # Indices for current class
    class_indices = (Y == cls)
    # Calculate accuracy
    class_accuracy = np.mean(Y_pred[class_indices] == Y[class_indices])
    per_class_accuracy[cls] = class_accuracy
# Display per-class accuracy
for cls, accuracy in per_class_accuracy.items():
    print(f"Class {LABEL_TO_CLASS[cls]}: Accuracy = {accuracy:.2%}")